In this project, we explore the integration of Electroencephalography (EEG) and Electromyography (EMG) signals for upper-limb gesture classification using the publicly available "EMG-EEG Dataset for Upper-Limb Gesture Classification"\cite{b1}. We employed a three-level fusion approach, combining data at the data level, feature level, and decision level. At the data level, raw EEG and EMG signals were synchronized and combined to create comprehensive input data. At the feature level, significant features were extracted from both signal types and merged to form a unified feature set. At the decision level, outputs from individual classifiers, trained separately on EEG and EMG features, were integrated to make final predictions. We detail the data processing steps, including preprocessing, feature extraction, and synchronization techniques, as well as the machine learning models used in our approach.
